{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-30T12:19:07.511575Z",
     "start_time": "2019-12-30T12:19:07.357094Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34m/home/skywatcher/datasets/data/cityscapes\u001b[00m\r\n",
      "├── \u001b[01;34mgtCoarse\u001b[00m\r\n",
      "│   ├── \u001b[01;34mtrain\u001b[00m\r\n",
      "│   ├── \u001b[01;34mtrain_extra\u001b[00m\r\n",
      "│   └── \u001b[01;34mval\u001b[00m\r\n",
      "├── \u001b[01;34mgtFine\u001b[00m\r\n",
      "│   ├── \u001b[01;34mtest\u001b[00m\r\n",
      "│   ├── \u001b[01;34mtrain\u001b[00m\r\n",
      "│   └── \u001b[01;34mval\u001b[00m\r\n",
      "└── \u001b[01;34mleftImg8bit\u001b[00m\r\n",
      "    ├── \u001b[01;34mtest\u001b[00m\r\n",
      "    ├── \u001b[01;34mtrain\u001b[00m\r\n",
      "    ├── \u001b[01;34mtrain_extra\u001b[00m\r\n",
      "    └── \u001b[01;34mval\u001b[00m\r\n",
      "\r\n",
      "13 directories\r\n"
     ]
    }
   ],
   "source": [
    "!tree -d -L 2 ~/datasets/data/cityscapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-30T13:17:44.758188Z",
     "start_time": "2019-12-30T13:17:44.747008Z"
    }
   },
   "outputs": [],
   "source": [
    "#Let's do some data preprocessing\n",
    "\n",
    "#Import the packages\n",
    "import os\n",
    "import glob\n",
    "from shutil import copy\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "'''\n",
    "Given a two lists of paths to images and masks, and two destination directories\n",
    "for the images and masks.\n",
    "'''\n",
    "def cs_create_copies(images, masks, image_dest, mask_dest, mask_only=False):\n",
    "    total = len(images)\n",
    "    image_count = 0\n",
    "    #For every image-mask pair\n",
    "    for image, mask in zip(images, masks):\n",
    "        #Get the filename we'll use\n",
    "        filename = image.split('/')[-1]\n",
    "        filename = filename[:filename.rindex('_')] + '.png'\n",
    "        #Create the symbolic links\n",
    "        if not mask_only:\n",
    "            os.symlink(image, image_dest + '/' + filename)\n",
    "        os.symlink(mask, mask_dest + '/' + filename)\n",
    "        image_count+=1\n",
    "        percentage = image_count/total*100\n",
    "        print('Copying Images and Masks: %d%%\\r'%(percentage),end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-30T12:19:13.606174Z",
     "start_time": "2019-12-30T12:19:13.595589Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "A utility function to match two lists of files, mainly used in \n",
    "cs_preprocessing_files to ensure that the recieved file names from glob\n",
    "match after each list has been sorted. This ensures that each image list is in the\n",
    "same order as its corresponding mask list. In the case its not, then something has gone\n",
    "wrong with the importing of files into the cityscapes directory.\n",
    "\n",
    "@param images - A list of image files, when used in cs_preprocessing_files it will be absolute paths to the files\n",
    "@param masks - A list of mask files, like images will be absolute when used in cs_preprocessing_files\n",
    "'''\n",
    "def cs_match_files(images, masks):\n",
    "    #If the two lists are of equal size\n",
    "    if len(images) == len(masks):\n",
    "        #Go through file by file in each list\n",
    "        for image, mask in zip(images, masks):\n",
    "            #Get the sequence for cityscapes\n",
    "            filename = image.split('/')[-1]\n",
    "            match_to = filename[:filename.rindex('_')]\n",
    "            #If the sequence isn't matching to the current mask then return False\n",
    "            if match_to not in mask:\n",
    "                print(\"The list hasn't been sorted properly\")\n",
    "                return False\n",
    "    #Lists don't have the same size! return False.\n",
    "    else:\n",
    "        print(\"Lengths of the images and masks list do not match!\")\n",
    "        return False\n",
    "    #Reaches here if all is good, so return True\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-30T13:15:22.354526Z",
     "start_time": "2019-12-30T13:15:22.339325Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "The task of this function will be to take the extracted cityscapes data\n",
    "given by source, which I will assume is a directory containing the following\n",
    "structure:\n",
    "cityscapes\n",
    "├── gtCoarse\n",
    "│   ├── train\n",
    "│   ├── train_extra\n",
    "│   └── val\n",
    "├── gtFine\n",
    "│   ├── test\n",
    "│   ├── train\n",
    "│   └── val\n",
    "└── leftImg8bit\n",
    "    ├── test\n",
    "    ├── train\n",
    "    ├── train_extra\n",
    "    └── val\n",
    "\n",
    "This will be the structure if you downloaded the cityscapes dataset and extracted it.\n",
    "The datasets you got should have been the leftImg8bit, leftImg8bit_trainextra, gtFine \n",
    "and gtCoarse.\n",
    "\n",
    "@param source - the directory for cityscapes that has the structure mentioned above (This is best done as an absolute path)\n",
    "\n",
    "'''\n",
    "def cs_preprocessing_files(source):\n",
    "    #Create all the variables\n",
    "    fine_masks_dir = source + '/train/masks/all'\n",
    "    coarse_masks_dir = source + '/train/coarse_masks/all'\n",
    "    fine_train_dir = source + '/train/images/all'\n",
    "    coarse_train_dir = source + '/train/coarse_images/all'\n",
    "    val_fine_masks_dir = source + '/val/masks/all'\n",
    "    val_coarse_masks_dir = source + '/val/coarse_masks/all'\n",
    "    val_images_dir = source + '/val/images/all'\n",
    "    \n",
    "    #Create all the directories\n",
    "    os.makedirs(fine_masks_dir, exist_ok=True)\n",
    "    os.makedirs(coarse_masks_dir, exist_ok=True)\n",
    "    os.makedirs(fine_train_dir, exist_ok=True)\n",
    "    os.makedirs(coarse_train_dir, exist_ok=True)\n",
    "    os.makedirs(val_fine_masks_dir, exist_ok=True)\n",
    "    os.makedirs(val_coarse_masks_dir, exist_ok=True)\n",
    "    os.makedirs(val_images_dir, exist_ok=True)\n",
    "    \n",
    "    #Get all the paths of the images and sort them\n",
    "    fine_images = glob.glob(source+'/leftImg8bit/train/*/*.png')\n",
    "    fine_images.sort()\n",
    "    coarse_images = fine_images + glob.glob(source + '/leftImg8bit/train_extra/*/*.png')\n",
    "    coarse_images.sort()\n",
    "    #Get all the masks and sort them\n",
    "    fine_masks = glob.glob(source+'/gtFine/train/*/*color*.png')\n",
    "    fine_masks.sort()\n",
    "    coarse_masks = glob.glob(source+'/gtCoarse/train*/*/*color*.png')\n",
    "    coarse_masks.sort()\n",
    "    \n",
    "    #Get all the validation paths and sort them\n",
    "    val_images = glob.glob(source+'/leftImg8bit/val/*/*.png')\n",
    "    val_images.sort()\n",
    "    val_fine_masks = glob.glob(source+'/gtFine/val/*/*color*.png')\n",
    "    val_fine_masks.sort()\n",
    "    val_coarse_masks = glob.glob(source+'/gtCoarse/val/*/*color*.png')\n",
    "    val_coarse_masks.sort()\n",
    "    \n",
    "    #Now verify all the paths have been retrieved and are in order\n",
    "    if cs_match_files(fine_images, fine_masks):\n",
    "        print('{} Fine Images and Masks Detected and in order'.format(len(fine_images)))\n",
    "    if cs_match_files(fine_images, fine_masks):\n",
    "        print('{} Coarse Images and Masks Detected and in order'.format(len(coarse_images)))\n",
    "    if cs_match_files(val_images, val_fine_masks):\n",
    "        print('{} Val Fine Images and Masks Detected and in order'.format(len(val_images)))\n",
    "    if cs_match_files(val_images, val_coarse_masks):\n",
    "        print('{} Val Coarse Images and Masks Detected and in order'.format(len(val_images)))\n",
    "    \n",
    "    #Now starting with the fine images, create the copies\n",
    "    print(\"Copying the Fine Images and Masks\")\n",
    "    cs_create_copies(fine_images, fine_masks, fine_train_dir, fine_masks_dir)\n",
    "    print(\"Copying the Fine Validation Images\")\n",
    "    cs_create_copies(val_images, val_fine_masks, val_images_dir, val_fine_masks_dir)\n",
    "    print(\"Copying the Coarse Images and Masks\")\n",
    "    cs_create_copies(coarse_images, coarse_masks, coarse_train_dir, coarse_masks_dir)\n",
    "    print(\"Copying the Coarse Validation Images and Masks\")\n",
    "    cs_create_copies(val_images, val_coarse_masks, val_images_dir, val_coarse_masks_dir, mask_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-30T13:14:04.177223Z",
     "start_time": "2019-12-30T13:14:04.166286Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "An ImageDataGenerator will be created using keras ready for use in training TF2.0 models\n",
    "like FastSCNN. \n",
    "\n",
    "@param images - The directory where all the training images are kept\n",
    "@param masks - The directory where all the masks are kept\n",
    "@param val_images - The directory where all validation images are kept\n",
    "@param val_masks - The directory where all validation masks are kept\n",
    "@param target_size - Should be a tuple of two numbers, the image size needed for the model should be put here. \n",
    "                     This will be largely dependent on the network you are training.\n",
    "@return ImageDataGenerator - The ImageDataGenerator\n",
    "'''\n",
    "def cs_create_generators(images, masks, val_images, val_masks, target_size):\n",
    "    \n",
    "    # we create two instances with the same arguments\n",
    "    data_gen_args = dict(rotation_range=90,\n",
    "                         width_shift_range=0.1,\n",
    "                         height_shift_range=0.1,\n",
    "                         zoom_range=0.2)\n",
    "    \n",
    "    image_datagen = ImageDataGenerator(**data_gen_args)\n",
    "    val_image_datagen = ImageDataGenerator()\n",
    "    mask_datagen = ImageDataGenerator(**data_gen_args)\n",
    "    val_mask_datagen = ImageDataGenerator()\n",
    "    \n",
    "    # Provide the same seed to the flow methods\n",
    "    seed = 42\n",
    "\n",
    "    #Create the generators\n",
    "    image_generator = image_datagen.flow_from_directory(\n",
    "        images,\n",
    "        class_mode=None,\n",
    "        follow_links=True,\n",
    "        seed=seed)\n",
    "\n",
    "    mask_generator = mask_datagen.flow_from_directory(\n",
    "        masks,\n",
    "        class_mode=None,\n",
    "        follow_links=True,\n",
    "        seed=seed)\n",
    "    \n",
    "    #Create the generators\n",
    "    val_image_generator = val_image_datagen.flow_from_directory(\n",
    "        val_images,\n",
    "        class_mode=None,\n",
    "        follow_links=True,\n",
    "        seed=seed)\n",
    "\n",
    "    val_mask_generator = val_mask_datagen.flow_from_directory(\n",
    "        val_masks,\n",
    "        class_mode=None,\n",
    "        follow_links=True,\n",
    "        seed=seed)\n",
    "\n",
    "    # combine generators into one which yields image and masks\n",
    "    train_generator = zip(image_generator, mask_generator)\n",
    "    val_generator = zip(val_image_generator, val_mask_generator)\n",
    "    return train_generator, val_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-30T13:22:34.560557Z",
     "start_time": "2019-12-30T13:17:49.665222Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2975 Fine Images and Masks Detected and in order\n",
      "22973 Coarse Images and Masks Detected and in order\n",
      "500 Val Fine Images and Masks Detected and in order\n",
      "500 Val Coarse Images and Masks Detected and in order\n",
      "Copying the Fine Images and Masks\n",
      "Copying the Fine Validation Images\n",
      "Copying the Coarse Images and Masks\n",
      "Copying the Coarse Validation Images and Masks\n",
      "Copying Images and Masks: 100%\r"
     ]
    }
   ],
   "source": [
    "cs_preprocessing_files('/home/skywatcher/datasets/data/cityscapes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-30T13:25:01.663657Z",
     "start_time": "2019-12-30T13:25:01.473984Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34m/home/skywatcher/datasets/data/cityscapes\u001b[00m\n",
      "├── \u001b[01;34mgtCoarse\u001b[00m\n",
      "│   ├── \u001b[01;34mtrain\u001b[00m\n",
      "│   ├── \u001b[01;34mtrain_extra\u001b[00m\n",
      "│   └── \u001b[01;34mval\u001b[00m\n",
      "├── \u001b[01;34mgtFine\u001b[00m\n",
      "│   ├── \u001b[01;34mtest\u001b[00m\n",
      "│   ├── \u001b[01;34mtrain\u001b[00m\n",
      "│   └── \u001b[01;34mval\u001b[00m\n",
      "├── \u001b[01;34mleftImg8bit\u001b[00m\n",
      "│   ├── \u001b[01;34mtest\u001b[00m\n",
      "│   ├── \u001b[01;34mtrain\u001b[00m\n",
      "│   ├── \u001b[01;34mtrain_extra\u001b[00m\n",
      "│   └── \u001b[01;34mval\u001b[00m\n",
      "├── \u001b[01;34mtrain\u001b[00m\n",
      "│   ├── \u001b[01;34mcoarse_images\u001b[00m\n",
      "│   ├── \u001b[01;34mcoarse_masks\u001b[00m\n",
      "│   ├── \u001b[01;34mimages\u001b[00m\n",
      "│   └── \u001b[01;34mmasks\u001b[00m\n",
      "└── \u001b[01;34mval\u001b[00m\n",
      "    ├── \u001b[01;34mcoarse_masks\u001b[00m\n",
      "    ├── \u001b[01;34mimages\u001b[00m\n",
      "    └── \u001b[01;34mmasks\u001b[00m\n",
      "\n",
      "22 directories\n"
     ]
    }
   ],
   "source": [
    "!tree -d -L 2 /home/skywatcher/datasets/data/cityscapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-30T13:27:32.001563Z",
     "start_time": "2019-12-30T13:26:20.518154Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2975 images belonging to 1 classes.\n",
      "Found 2975 images belonging to 1 classes.\n",
      "Found 500 images belonging to 1 classes.\n",
      "Found 500 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "images = '/home/skywatcher/datasets/data/cityscapes/train/images'\n",
    "masks = '/home/skywatcher/datasets/data/cityscapes/train/masks'\n",
    "val_images = '/home/skywatcher/datasets/data/cityscapes/val/images'\n",
    "val_masks = '/home/skywatcher/datasets/data/cityscapes/val/masks'\n",
    "train_generator, val_generator = cs_create_generators(images, masks, val_images, val_masks, (224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
