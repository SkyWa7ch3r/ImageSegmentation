{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-30T14:43:46.817169Z",
     "start_time": "2019-12-30T14:43:46.656890Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34m/home/skywatcher/datasets/data/cityscapes\u001b[00m\r\n",
      "├── \u001b[01;34mgtCoarse\u001b[00m\r\n",
      "│   ├── \u001b[01;34mtrain\u001b[00m\r\n",
      "│   ├── \u001b[01;34mtrain_extra\u001b[00m\r\n",
      "│   └── \u001b[01;34mval\u001b[00m\r\n",
      "├── \u001b[01;34mgtFine\u001b[00m\r\n",
      "│   ├── \u001b[01;34mtest\u001b[00m\r\n",
      "│   ├── \u001b[01;34mtrain\u001b[00m\r\n",
      "│   └── \u001b[01;34mval\u001b[00m\r\n",
      "└── \u001b[01;34mleftImg8bit\u001b[00m\r\n",
      "    ├── \u001b[01;34mtest\u001b[00m\r\n",
      "    ├── \u001b[01;34mtrain\u001b[00m\r\n",
      "    ├── \u001b[01;34mtrain_extra\u001b[00m\r\n",
      "    └── \u001b[01;34mval\u001b[00m\r\n",
      "\r\n",
      "13 directories\r\n"
     ]
    }
   ],
   "source": [
    "!tree -d -L 2 ~/datasets/data/cityscapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-30T14:43:49.150024Z",
     "start_time": "2019-12-30T14:43:47.766379Z"
    }
   },
   "outputs": [],
   "source": [
    "#Let's do some data preprocessing\n",
    "\n",
    "#Import the packages\n",
    "import os\n",
    "import glob\n",
    "from shutil import copy\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "'''\n",
    "Given a two lists of paths to images and masks, and two destination directories\n",
    "for the images and masks.\n",
    "'''\n",
    "def cs_create_copies(images, masks, image_dest, mask_dest, mask_only=False):\n",
    "    total = len(images)\n",
    "    image_count = 0\n",
    "    #For every image-mask pair\n",
    "    for image, mask in zip(images, masks):\n",
    "        #Get the filename we'll use\n",
    "        filename = image.split('/')[-1]\n",
    "        filename = filename[:filename.rindex('_')] + '.png'\n",
    "        #Create the symbolic links\n",
    "        if not mask_only:\n",
    "            os.symlink(image, image_dest + '/' + filename)\n",
    "        os.symlink(mask, mask_dest + '/' + filename)\n",
    "        image_count+=1\n",
    "        percentage = image_count/total*100\n",
    "        print('Copying Images and Masks: %d%%\\r'%(percentage),end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-30T14:43:49.203363Z",
     "start_time": "2019-12-30T14:43:49.197240Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "A utility function to match two lists of files, mainly used in \n",
    "cs_preprocessing_files to ensure that the recieved file names from glob\n",
    "match after each list has been sorted. This ensures that each image list is in the\n",
    "same order as its corresponding mask list. In the case its not, then something has gone\n",
    "wrong with the importing of files into the cityscapes directory.\n",
    "\n",
    "@param images - A list of image files, when used in cs_preprocessing_files it will be absolute paths to the files\n",
    "@param masks - A list of mask files, like images will be absolute when used in cs_preprocessing_files\n",
    "'''\n",
    "def cs_match_files(images, masks):\n",
    "    #If the two lists are of equal size\n",
    "    if len(images) == len(masks):\n",
    "        #Go through file by file in each list\n",
    "        for image, mask in zip(images, masks):\n",
    "            #Get the sequence for cityscapes\n",
    "            filename = image.split('/')[-1]\n",
    "            match_to = filename[:filename.rindex('_')]\n",
    "            #If the sequence isn't matching to the current mask then return False\n",
    "            if match_to not in mask:\n",
    "                print(\"The list hasn't been sorted properly\")\n",
    "                return False\n",
    "    #Lists don't have the same size! return False.\n",
    "    else:\n",
    "        print(\"Lengths of the images and masks list do not match!\")\n",
    "        return False\n",
    "    #Reaches here if all is good, so return True\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-30T14:43:49.281423Z",
     "start_time": "2019-12-30T14:43:49.253676Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "The task of this function will be to take the extracted cityscapes data\n",
    "given by source, which I will assume is a directory containing the following\n",
    "structure:\n",
    "cityscapes\n",
    "├── gtCoarse\n",
    "│   ├── train\n",
    "│   ├── train_extra\n",
    "│   └── val\n",
    "├── gtFine\n",
    "│   ├── test\n",
    "│   ├── train\n",
    "│   └── val\n",
    "└── leftImg8bit\n",
    "    ├── test\n",
    "    ├── train\n",
    "    ├── train_extra\n",
    "    └── val\n",
    "\n",
    "This will be the structure if you downloaded the cityscapes dataset and extracted it.\n",
    "The datasets you got should have been the leftImg8bit, leftImg8bit_trainextra, gtFine \n",
    "and gtCoarse.\n",
    "\n",
    "@param source - the directory for cityscapes that has the structure mentioned above (This is best done as an absolute path)\n",
    "\n",
    "'''\n",
    "def cs_preprocessing_files(source):\n",
    "    #Create all the variables\n",
    "    fine_masks_dir = source + '/train/masks//all'\n",
    "    coarse_masks_dir = source + '/train/coarse_masks/all'\n",
    "    fine_train_dir = source + '/train/images/all'\n",
    "    coarse_train_dir = source + '/train/coarse_images/all'\n",
    "    val_fine_masks_dir = source + '/val/masks/all'\n",
    "    val_coarse_masks_dir = source + '/val/coarse_masks/all'\n",
    "    val_images_dir = source + '/val/images/all'\n",
    "    \n",
    "    #Create all the directories\n",
    "    os.makedirs(fine_masks_dir, exist_ok=True)\n",
    "    os.makedirs(coarse_masks_dir, exist_ok=True)\n",
    "    os.makedirs(fine_train_dir, exist_ok=True)\n",
    "    os.makedirs(coarse_train_dir, exist_ok=True)\n",
    "    os.makedirs(val_fine_masks_dir, exist_ok=True)\n",
    "    os.makedirs(val_coarse_masks_dir, exist_ok=True)\n",
    "    os.makedirs(val_images_dir, exist_ok=True)\n",
    "    \n",
    "    #Get all the paths of the images and sort them\n",
    "    fine_images = glob.glob(source+'/leftImg8bit/train/*/*.png')\n",
    "    fine_images.sort()\n",
    "    coarse_images = fine_images + glob.glob(source + '/leftImg8bit/train_extra/*/*.png')\n",
    "    coarse_images.sort()\n",
    "    #Get all the masks and sort them\n",
    "    fine_masks = glob.glob(source+'/gtFine/train/*/*color*.png')\n",
    "    fine_masks.sort()\n",
    "    coarse_masks = glob.glob(source+'/gtCoarse/train*/*/*color*.png')\n",
    "    coarse_masks.sort()\n",
    "    \n",
    "    #Get all the validation paths and sort them\n",
    "    val_images = glob.glob(source+'/leftImg8bit/val/*/*.png')\n",
    "    val_images.sort()\n",
    "    val_fine_masks = glob.glob(source+'/gtFine/val/*/*color*.png')\n",
    "    val_fine_masks.sort()\n",
    "    val_coarse_masks = glob.glob(source+'/gtCoarse/val/*/*color*.png')\n",
    "    val_coarse_masks.sort()\n",
    "    \n",
    "    #Now verify all the paths have been retrieved and are in order\n",
    "    if cs_match_files(fine_images, fine_masks):\n",
    "        print('{} Fine Images and Masks Detected and in order'.format(len(fine_images)))\n",
    "    if cs_match_files(fine_images, fine_masks):\n",
    "        print('{} Coarse Images and Masks Detected and in order'.format(len(coarse_images)))\n",
    "    if cs_match_files(val_images, val_fine_masks):\n",
    "        print('{} Val Fine Images and Masks Detected and in order'.format(len(val_images)))\n",
    "    if cs_match_files(val_images, val_coarse_masks):\n",
    "        print('{} Val Coarse Images and Masks Detected and in order'.format(len(val_images)))\n",
    "    \n",
    "    #Now starting with the fine images, create the copies\n",
    "    print(\"Copying the Fine Images and Masks\")\n",
    "    cs_create_copies(fine_images, fine_masks, fine_train_dir, fine_masks_dir)\n",
    "    print(\"Copying the Fine Validation Images\")\n",
    "    cs_create_copies(val_images, val_fine_masks, val_images_dir, val_fine_masks_dir)\n",
    "    print(\"Copying the Coarse Images and Masks\")\n",
    "    cs_create_copies(coarse_images, coarse_masks, coarse_train_dir, coarse_masks_dir)\n",
    "    print(\"Copying the Coarse Validation Images and Masks\")\n",
    "    cs_create_copies(val_images, val_coarse_masks, val_images_dir, val_coarse_masks_dir, mask_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-30T15:22:20.696629Z",
     "start_time": "2019-12-30T15:22:20.681090Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "An ImageDataGenerator will be created using keras ready for use in training TF2.0 models\n",
    "like FastSCNN. \n",
    "\n",
    "@param images - The directory where all the training images are kept\n",
    "@param masks - The directory where all the masks are kept\n",
    "@param val_images - The directory where all validation images are kept\n",
    "@param val_masks - The directory where all validation masks are kept\n",
    "@param target_size - Should be a tuple of two numbers, the image size needed for the model should be put here. \n",
    "                     This will be largely dependent on the network you are training.\n",
    "@return ImageDataGenerator - The ImageDataGenerator\n",
    "'''\n",
    "def cs_create_generators(images, masks, val_images, val_masks, target_size):\n",
    "    \n",
    "    # we create two instances with the same arguments\n",
    "    data_gen_args = dict(rotation_range=90,\n",
    "                         width_shift_range=0.1,\n",
    "                         height_shift_range=0.1,\n",
    "                         zoom_range=0.2,\n",
    "                         rescale=1/255)\n",
    "    \n",
    "    image_datagen = ImageDataGenerator(**data_gen_args)\n",
    "    val_image_datagen = ImageDataGenerator()\n",
    "    mask_datagen = ImageDataGenerator(**data_gen_args)\n",
    "    val_mask_datagen = ImageDataGenerator()\n",
    "    \n",
    "    # Provide the same seed to the flow methods\n",
    "    seed = 42\n",
    "\n",
    "    #Create the generators\n",
    "    image_generator = image_datagen.flow_from_directory(\n",
    "        images,\n",
    "        class_mode=None,\n",
    "        follow_links=True,\n",
    "        target_size=target_size,\n",
    "        seed=seed)\n",
    "\n",
    "    mask_generator = mask_datagen.flow_from_directory(\n",
    "        masks,\n",
    "        class_mode=None,\n",
    "        follow_links=True,\n",
    "        target_size=target_size,\n",
    "        seed=seed)\n",
    "    \n",
    "    #Create the generators\n",
    "    val_image_generator = val_image_datagen.flow_from_directory(\n",
    "        val_images,\n",
    "        class_mode=None,\n",
    "        follow_links=True,\n",
    "        target_size=target_size,\n",
    "        seed=seed)\n",
    "\n",
    "    val_mask_generator = val_mask_datagen.flow_from_directory(\n",
    "        val_masks,\n",
    "        class_mode=None,\n",
    "        follow_links=True,\n",
    "        target_size=target_size,\n",
    "        seed=seed)\n",
    "\n",
    "    # combine generators into one which yields image and masks\n",
    "    train_generator = (pair for pair in zip(image_generator, mask_generator))\n",
    "    val_generator = (pair for pair in zip(val_image_generator, val_mask_generator))\n",
    "    return train_generator, val_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-30T14:48:35.344140Z",
     "start_time": "2019-12-30T14:43:50.309080Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2975 Fine Images and Masks Detected and in order\n",
      "22973 Coarse Images and Masks Detected and in order\n",
      "500 Val Fine Images and Masks Detected and in order\n",
      "500 Val Coarse Images and Masks Detected and in order\n",
      "Copying the Fine Images and Masks\n",
      "Copying the Fine Validation Images\n",
      "Copying the Coarse Images and Masks\n",
      "Copying the Coarse Validation Images and Masks\n",
      "Copying Images and Masks: 100%\r"
     ]
    }
   ],
   "source": [
    "cs_preprocessing_files('/home/skywatcher/datasets/data/cityscapes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-30T14:48:35.570649Z",
     "start_time": "2019-12-30T14:48:35.392761Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34m/home/skywatcher/datasets/data/cityscapes\u001b[00m\n",
      "├── \u001b[01;34mgtCoarse\u001b[00m\n",
      "│   ├── \u001b[01;34mtrain\u001b[00m\n",
      "│   ├── \u001b[01;34mtrain_extra\u001b[00m\n",
      "│   └── \u001b[01;34mval\u001b[00m\n",
      "├── \u001b[01;34mgtFine\u001b[00m\n",
      "│   ├── \u001b[01;34mtest\u001b[00m\n",
      "│   ├── \u001b[01;34mtrain\u001b[00m\n",
      "│   └── \u001b[01;34mval\u001b[00m\n",
      "├── \u001b[01;34mleftImg8bit\u001b[00m\n",
      "│   ├── \u001b[01;34mtest\u001b[00m\n",
      "│   ├── \u001b[01;34mtrain\u001b[00m\n",
      "│   ├── \u001b[01;34mtrain_extra\u001b[00m\n",
      "│   └── \u001b[01;34mval\u001b[00m\n",
      "├── \u001b[01;34mtrain\u001b[00m\n",
      "│   ├── \u001b[01;34mcoarse_images\u001b[00m\n",
      "│   ├── \u001b[01;34mcoarse_masks\u001b[00m\n",
      "│   ├── \u001b[01;34mimages\u001b[00m\n",
      "│   └── \u001b[01;34mmasks\u001b[00m\n",
      "└── \u001b[01;34mval\u001b[00m\n",
      "    ├── \u001b[01;34mcoarse_masks\u001b[00m\n",
      "    ├── \u001b[01;34mimages\u001b[00m\n",
      "    └── \u001b[01;34mmasks\u001b[00m\n",
      "\n",
      "22 directories\n"
     ]
    }
   ],
   "source": [
    "!tree -d -L 2 /home/skywatcher/datasets/data/cityscapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-30T15:23:14.830286Z",
     "start_time": "2019-12-30T15:22:22.791975Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2975 images belonging to 1 classes.\n",
      "Found 2975 images belonging to 1 classes.\n",
      "Found 500 images belonging to 1 classes.\n",
      "Found 500 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "images = '/home/skywatcher/datasets/data/cityscapes/train/images'\n",
    "masks = '/home/skywatcher/datasets/data/cityscapes/train/masks'\n",
    "val_images = '/home/skywatcher/datasets/data/cityscapes/val/images'\n",
    "val_masks = '/home/skywatcher/datasets/data/cityscapes/val/masks'\n",
    "train_generator, val_generator = cs_create_generators(images, masks, val_images, val_masks, (2048, 1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-30T15:23:17.223372Z",
     "start_time": "2019-12-30T15:23:14.890985Z"
    }
   },
   "outputs": [],
   "source": [
    "import fast_scnn\n",
    "fastscnn = fast_scnn.create_fastscnn()\n",
    "optimizer = tf.keras.optimizers.SGD(momentum=0.9, lr=0.045)\n",
    "fastscnn.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-30T15:23:47.124708Z",
     "start_time": "2019-12-30T15:23:17.279770Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "A target array with shape (32, 2048, 1024, 3) was passed for an output of shape (None, 2048, 1024, 19) while using as loss `categorical_crossentropy`. This loss expects targets to have the same shape as the output.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-cc1da7780ddb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m170\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         validation_steps=32)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1295\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1296\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1297\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m   1298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1299\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m       \u001b[0mis_deferred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m       \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m    971\u001b[0m       outputs = training_v2_utils.train_on_batch(\n\u001b[1;32m    972\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 973\u001b[0;31m           class_weight=class_weight, reset_metrics=reset_metrics)\n\u001b[0m\u001b[1;32m    974\u001b[0m       outputs = (outputs['total_loss'] + outputs['output_losses'] +\n\u001b[1;32m    975\u001b[0m                  outputs['metrics'])\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(model, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m    251\u001b[0m   x, y, sample_weights = model._standardize_user_data(\n\u001b[1;32m    252\u001b[0m       \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m       extract_tensors_from_dataset=True)\n\u001b[0m\u001b[1;32m    254\u001b[0m   \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpand_composites\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m   \u001b[0;31m# If `model._distribution_strategy` is True, then we are in a replica context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[1;32m   2536\u001b[0m           \u001b[0;31m# Additional checks to avoid users mistakenly using improper loss fns.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2537\u001b[0m           training_utils.check_loss_and_target_compatibility(\n\u001b[0;32m-> 2538\u001b[0;31m               y, self._feed_loss_fns, feed_output_shapes)\n\u001b[0m\u001b[1;32m   2539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2540\u001b[0m       \u001b[0;31m# If sample weight mode has not been set and weights are None for all the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mcheck_loss_and_target_compatibility\u001b[0;34m(targets, loss_fns, output_shapes)\u001b[0m\n\u001b[1;32m    741\u001b[0m           raise ValueError('A target array with shape ' + str(y.shape) +\n\u001b[1;32m    742\u001b[0m                            \u001b[0;34m' was passed for an output of shape '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 743\u001b[0;31m                            \u001b[0;34m' while using as loss `'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloss_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'`. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    744\u001b[0m                            \u001b[0;34m'This loss expects targets to have the same shape '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    745\u001b[0m                            'as the output.')\n",
      "\u001b[0;31mValueError\u001b[0m: A target array with shape (32, 2048, 1024, 3) was passed for an output of shape (None, 2048, 1024, 19) while using as loss `categorical_crossentropy`. This loss expects targets to have the same shape as the output."
     ]
    }
   ],
   "source": [
    "fastscnn.fit_generator(\n",
    "        train_generator,\n",
    "        epochs=5,\n",
    "        steps_per_epoch=170,\n",
    "        validation_data=val_generator,\n",
    "        validation_steps=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-30T15:23:47.174474Z",
     "start_time": "2019-12-30T15:22:26.689Z"
    }
   },
   "outputs": [],
   "source": [
    "fastscnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-30T15:23:47.216464Z",
     "start_time": "2019-12-30T15:22:26.908Z"
    }
   },
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(fastscnn, show_layer_names=True, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
